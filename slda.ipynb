{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import re\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "# import tomotopy as tp\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n",
    "tokenizer = RegexpTokenizer(r\"\\w+\")\n",
    "\n",
    "\n",
    "def preprocess_text(text: str):\n",
    "    return \" \".join(\n",
    "        [\n",
    "            stemmer.stem(word)\n",
    "            for word in tokenizer.tokenize(\n",
    "                \" \".join([re.sub(r\"\\s+\", \" \", word) for word in text.split()])\n",
    "            )\n",
    "        ]\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path.cwd() / \"data\" / \"findal_df.json\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(data_path).dropna(subset=\"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text_pp'] = df['text'].apply(lambda x: preprocess_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       workshop track 1st confer on lifelong learn ag...\n",
       "1       arxiv 1410 3831v1 stat ml 14 oct 2014an exact ...\n",
       "2       learn gener model across incompar space charlo...\n",
       "3       on the gener abil of onlin learn algorithm for...\n",
       "4       geometr understand of deep learn na lei zhongx...\n",
       "                              ...                        \n",
       "1230    music word embed bridg the gap between listen ...\n",
       "1231    metric for multi class classif anoverview a w ...\n",
       "1232    intellig play dice stochast is essenti for mac...\n",
       "1233    can automl outperform human an evalu on popula...\n",
       "1234    set valu and variat analysi manuscript no will...\n",
       "Name: text_pp, Length: 1223, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"text_pp\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_vectorizer = CountVectorizer(\n",
    "    ngram_range=(1, 3),\n",
    "    max_df=0.75,\n",
    "    min_df=0.01,\n",
    "    tokenizer=tokenizer.tokenize,\n",
    "    stop_words=\"english\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jakubwujec/.pyenv/versions/3.10.1/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tf = tf_vectorizer.fit_transform(df['text_pp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 29\u001b[0m\n\u001b[1;32m     23\u001b[0m         slda\u001b[38;5;241m.\u001b[39mtrain(\u001b[38;5;241m20\u001b[39m)\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m slda\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mone_model_eval\u001b[39m(\n\u001b[0;32m---> 29\u001b[0m     model: \u001b[43mtp\u001b[49m\u001b[38;5;241m.\u001b[39mSLDAModel, X_test: pd\u001b[38;5;241m.\u001b[39mDataFrame, y_test: pd\u001b[38;5;241m.\u001b[39mSeries\n\u001b[1;32m     30\u001b[0m ):\n\u001b[1;32m     31\u001b[0m     test_preds \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(X_test)):\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tp' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from pyparsing import Any\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "\n",
    "\n",
    "def _get_params_combinations(\n",
    "    self, hyper_params: dict[str, list]\n",
    ") -> list[dict]:\n",
    "    keys, values = zip(*hyper_params.items())\n",
    "    return [dict(zip(keys, v)) for v in itertools.product(*values)]\n",
    "\n",
    "\n",
    "def one_model_train(\n",
    "    X_train: pd.DataFrame, y_train: pd.Series, params: dict[str, Any]\n",
    "):\n",
    "    slda = tp.SLDAModel(**params)\n",
    "    for i in range(0, len(X_train)):\n",
    "        slda.add_doc(\n",
    "            X_train.iloc[i].strip().split(), y=[float(np.array(y_train)[i])]\n",
    "        )\n",
    "    for i in range(0, 1020, 20):\n",
    "        slda.train(20)\n",
    "\n",
    "    return slda\n",
    "\n",
    "\n",
    "def one_model_eval(\n",
    "    model: tp.SLDAModel, X_test: pd.DataFrame, y_test: pd.Series\n",
    "):\n",
    "    test_preds = []\n",
    "    for i in range(0, len(X_test)):\n",
    "        slda_test_doc = model.make_doc(list(X_test)[i])\n",
    "        model.infer(slda_test_doc)\n",
    "        test_preds.append(float(model.estimate(slda_test_doc)))\n",
    "\n",
    "    return mean_absolute_percentage_error(y_true=y_test, y_pred=test_preds)\n",
    "\n",
    "\n",
    "def model_cross_validate(\n",
    "    X: pd.DataFrame, y: pd.Series, params: dict[str, Any]\n",
    "):\n",
    "    results = []\n",
    "    kf = KFold(n_splits=3)\n",
    "\n",
    "    for i, (train_index, test_index) in enumerate(kf.split(X)):\n",
    "        X_train, y_train = X.iloc[train_index], y.iloc[train_index]\n",
    "        X_test, y_test = X.iloc[test_index], y.iloc[test_index]\n",
    "\n",
    "        model = one_model_train(X_train=X_test, y_train=y_train, params=params)\n",
    "        result = one_model_eval(model=model, X_test=X_test, y_test=y_test)\n",
    "        result.append(results)\n",
    "\n",
    "    return {**params, \"mape\": np.mean(results)}\n",
    "\n",
    "\n",
    "def hypreropt(\n",
    "    X: pd.DataFrame,\n",
    "    y: pd.Series,\n",
    "    hyper_params: dict[str, list],\n",
    ") -> pd.DataFrame:\n",
    "    params_combinations = _get_params_combinations(hyper_params)\n",
    "\n",
    "    results = []\n",
    "    for params in params_combinations:\n",
    "        result = model_cross_validate(X=X, y=y, params=params)\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit ('3.10.1')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "55729c9ac2c7dbad6f6d23b8a61c7691f855a2bc34416b74858e7ea5b72a26bc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
