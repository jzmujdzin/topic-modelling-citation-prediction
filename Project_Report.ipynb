{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9cda7bde-b393-4412-b4f7-12b9873f7fbc",
   "metadata": {},
   "source": [
    "# Topic Modelling - Citation Prediction Project\n",
    "By Jakub Wujec and Jakub Żmujdzin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ad719e-c71c-4d83-842d-58a7160334e2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Abstract\n",
    "This project aims to develop an article citation prediction model for identifying and categorizing articles for use in topic modelling. We examine the text of the articles to identify common semantics and categories, and use machine learning techniques to build predictive models based on these observations. We then use our model to evaluate its accuracy in predicting citation count. Our proposed model will involve utilizing natural language processing (NLP) techniques such as topic modeling, document-term matrices to extract features from the articles and build predictive models. We will also used supervised tree bosting algorithm (XGBoost) to predict the citation score based on topics present in an article. The research mainly focuses on identifying topics which are more \"hot\" in case of citations, not particularly to correctly predict citation count of an article. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbdaf98a-46f7-480e-afab-6ab44080fa98",
   "metadata": {},
   "source": [
    "## Keywords\n",
    "Topic modelling, XGBoost, citation, regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab07c79-9807-47b8-9246-8008b08b868d",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d54a600-5a24-49ff-b04c-0b748f943b99",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "df = pd.read_json(Path.cwd() / \"final_df\" / \"final_df.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad14b940-f394-4226-8314-ccb1abfa12c9",
   "metadata": {},
   "source": [
    "### Research questions\n",
    "some research q\n",
    "### Motivation standing for undertaking the topic\n",
    "some motivation text \n",
    "### Methodology\n",
    "- Dataset source & presentation <br>\n",
    "The dataset is available in final_df/final_df.json directory. \n",
    "To construct this dataset, we have used arXiv API and google scholar. Using arXiv API, we have searched with \"machine learning\" query to download article's titles, authors and links to PDF files containing the text. Then, we used BeautifulSoup to scrap Google Scholar. For each article in a dataframe, we have searched in Google Scholar for article's title and article's authors, then extracted citation count, if it was available. Finally, we used PyPDF2 to download PDF files from the links we have scrapped earlier, from arXiv. We have saved the articles to a json file, containing publication's title, text and citation score.\n",
    "Finally, we have arrived at 1234 articles, of which 12 were wrongly decoded. Those articles were discarded. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd8f777a-0a6d-4b58-9c29-9e5b8b862763",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>link</th>\n",
       "      <th>citations</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Continual Reinforcement Learning with TELLA</td>\n",
       "      <td>http://arxiv.org/pdf/2208.04287v1</td>\n",
       "      <td>2</td>\n",
       "      <td>Workshop Track - 1st Conference on Lifelong Le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>An exact mapping between the Variational Renor...</td>\n",
       "      <td>http://arxiv.org/pdf/1410.3831v1</td>\n",
       "      <td>295</td>\n",
       "      <td>arXiv:1410.3831v1  [stat.ML]  14 Oct 2014An ex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Learning Generative Models across Incomparable...</td>\n",
       "      <td>http://arxiv.org/pdf/1905.05461v2</td>\n",
       "      <td>69</td>\n",
       "      <td>Learning Generative Models across Incomparable...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>On the Generalization Ability of Online Learni...</td>\n",
       "      <td>http://arxiv.org/pdf/1305.2505v1</td>\n",
       "      <td>74</td>\n",
       "      <td>On the Generalization Ability of Online Learni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Geometric Understanding of Deep Learning</td>\n",
       "      <td>http://arxiv.org/pdf/1805.10451v2</td>\n",
       "      <td>110</td>\n",
       "      <td>Geometric Understanding of Deep Learning\\nNa L...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0        Continual Reinforcement Learning with TELLA   \n",
       "1  An exact mapping between the Variational Renor...   \n",
       "2  Learning Generative Models across Incomparable...   \n",
       "3  On the Generalization Ability of Online Learni...   \n",
       "4           Geometric Understanding of Deep Learning   \n",
       "\n",
       "                                link  citations  \\\n",
       "0  http://arxiv.org/pdf/2208.04287v1          2   \n",
       "1   http://arxiv.org/pdf/1410.3831v1        295   \n",
       "2  http://arxiv.org/pdf/1905.05461v2         69   \n",
       "3   http://arxiv.org/pdf/1305.2505v1         74   \n",
       "4  http://arxiv.org/pdf/1805.10451v2        110   \n",
       "\n",
       "                                                text  \n",
       "0  Workshop Track - 1st Conference on Lifelong Le...  \n",
       "1  arXiv:1410.3831v1  [stat.ML]  14 Oct 2014An ex...  \n",
       "2  Learning Generative Models across Incomparable...  \n",
       "3  On the Generalization Ability of Online Learni...  \n",
       "4  Geometric Understanding of Deep Learning\\nNa L...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59897c16-49a0-4f79-8fd8-6413c0a90f6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7285b78-6dee-4789-8920-624131d03e0d",
   "metadata": {},
   "source": [
    "- code for data cleaning and preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9df5e2-6017-47be-806f-9d10772a324a",
   "metadata": {},
   "source": [
    "We have used Porter Stemmer and Regexp Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cfee65c-c746-416d-a0bb-e41b850229d7",
   "metadata": {},
   "source": [
    "do not run the cell below - it is just for presentation purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308a93bd-72e2-4660-9099-1b9e2e47ff2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n",
    "tokenizer = RegexpTokenizer(r'\\w+')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf23efb-2100-49cc-adf8-a54d4faaa7f0",
   "metadata": {},
   "source": [
    "We have constructed a lengthy and chaotic function ```preprocess_text```, which (believe us), in order, does this: <br>\n",
    "- [x] Gets rid of whitespace and numbers ```re.sub(r\"[\\s\\d]+\", \" \", word)```\n",
    "- [x] Gets rid of LaTex equations ```re.sub(r\"(\\${1,2})(?:(?!\\1)[\\s\\S])*\\1\", ... ```\n",
    "- [x] Tokenizes the words ``` tokenizer.tokenize(... ```\n",
    "- [x] Gets rid of words that are shorter than 2 characters ``` if len(word) > 2 ```\n",
    "- [x] Gets rid of \"special\" words we have identified as useless ```word not in [ ... ] ```\n",
    "- [x] Stems the result of it all\n",
    "\n",
    "Finally, we have applied CountVectorizer to the output.\n",
    "- [x] Using max_df and min_df we have gotten rid of too rare or too frequent words\n",
    "- [x] Using stop_words='english' we have gotten rid of english stopwords\n",
    "- [x] We have extracted word ngrams in the boundaries of (1, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a93ea27-c20b-4018-ae8e-68ef86503f72",
   "metadata": {},
   "source": [
    "do not run the cell below - it is just for presentation purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817948f7-02b3-451d-8ca9-95a08cd21604",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text: str):\n",
    "    return \" \".join(\n",
    "        [\n",
    "            stemmer.stem(word)\n",
    "            if len(word) > 2\n",
    "            and word\n",
    "            not in [\n",
    "                \"uni\",\n",
    "                \"uni uni\",\n",
    "                \"uni uni uni\",\n",
    "                \"ieee\",\n",
    "                \"doi\",\n",
    "                \"vextendsingl\",\n",
    "                \"http\",\n",
    "                \"https\",\n",
    "                \"vextenddoubl\",\n",
    "                \"parenrightbig\",\n",
    "                \"parenleftbig\",\n",
    "            ]\n",
    "            else \"\"\n",
    "            for word in tokenizer.tokenize(\n",
    "                \" \".join(\n",
    "                    [\n",
    "                        re.sub(\n",
    "                            r\"(\\${1,2})(?:(?!\\1)[\\s\\S])*\\1\",\n",
    "                            \" \",\n",
    "                            re.sub(r\"[\\s\\d]+\", \" \", word),\n",
    "                        )\n",
    "                        for word in text.split()\n",
    "                    ]\n",
    "                )\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "tf_vectorizer = CountVectorizer(ngram_range = (1, 4),\n",
    "                                max_df = 0.8,\n",
    "                                min_df = 0.01,\n",
    "                                tokenizer = tokenizer.tokenize,\n",
    "                                stop_words='english'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd81502-8e0c-4460-9c1e-0a4f130ff02e",
   "metadata": {},
   "source": [
    "- Our fitted topic model is available in the model.pkl file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20e47c85-7b70-405e-bf52-eddbb99d9a1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LatentDirichletAllocation(learning_decay=0.6, learning_offset=30, max_iter=150,\n",
       "                          mean_change_tol=0.01, n_components=5, n_jobs=-1,\n",
       "                          verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LatentDirichletAllocation</label><div class=\"sk-toggleable__content\"><pre>LatentDirichletAllocation(learning_decay=0.6, learning_offset=30, max_iter=150,\n",
       "                          mean_change_tol=0.01, n_components=5, n_jobs=-1,\n",
       "                          verbose=1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LatentDirichletAllocation(learning_decay=0.6, learning_offset=30, max_iter=150,\n",
       "                          mean_change_tol=0.01, n_components=5, n_jobs=-1,\n",
       "                          verbose=1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "lda = pickle.load(open('model.pkl', 'rb'))\n",
    "lda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c134987-c6f8-44ba-9f4f-53051ee8802d",
   "metadata": {},
   "source": [
    "### Reasons for choosing methods\n",
    "some reasons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531fa647-7e7b-4dee-9d3a-9b392f4a685c",
   "metadata": {},
   "source": [
    "## Presentation and interpretation of results\n",
    "Aggregated Profiles plot:\n",
    "<br>\n",
    "<img src=\"https://raw.githubusercontent.com/jzmujdzin/topic-modelling-citation-prediction/main/agg_profiles_static.png\">\n",
    "<br>\n",
    "Interactive plot (html link):\n",
    "<a href=\"agg_profiles.html\" target=\"_blank\">here</a>\n",
    "<br> <br>\n",
    "Some interpratation for agg profiles\n",
    "<br> <br>\n",
    "Variable importance plot:\n",
    "<br>\n",
    "<img src=\"https://raw.githubusercontent.com/jzmujdzin/topic-modelling-citation-prediction/main/var_importance_static.png\">\n",
    "<br>\n",
    "Interactive plot (html link):\n",
    "<a href=\"var_importance.html\" target=\"_blank\">here</a>\n",
    "<br> <br>\n",
    "Some interpretation for var importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978d7ab6-108f-49b7-a0bd-f82f46a63d4a",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "veryfing previously stated reserach questions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
